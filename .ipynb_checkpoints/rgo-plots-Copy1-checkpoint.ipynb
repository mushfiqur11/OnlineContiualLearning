{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import sys\n",
    "import numpy as np\n",
    "from scipy.integrate import simps\n",
    "import matplotlib.colors as colors\n",
    "import matplotlib.cm as cmx\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.figure as figure\n",
    "import matplotlib.patches as mpatches\n",
    "from matplotlib.ticker import FormatStrFormatter\n",
    "from six.moves import cPickle as pickle\n",
    "from scipy.spatial.distance import cosine\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import rc\n",
    "rc('font',**{'family':'sans-serif','sans-serif':['Helvetica']})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions\n",
    "def unpickle_data(pickle_file):\n",
    "    \"\"\"\n",
    "    Unpickles the data from a pickle file\n",
    "    \"\"\"\n",
    "    f = open(pickle_file, 'rb')\n",
    "    return pickle.load(f)\n",
    "\n",
    "def populate_data_dict(data_dict, key, pickle_file):\n",
    "    \"\"\"\n",
    "    Given a key populates a dictionary\n",
    "    \"\"\"\n",
    "    data_dict[key] = unpickle_data(pickle_file)\n",
    "    \n",
    "    \n",
    "def populate_k_shot_acc_dict(data_dict, key, k_shot_dict):\n",
    "    num_runs = data_dict[key]['mean'].shape[0]\n",
    "    k_shot_dict[key] = []\n",
    "    for run in range(num_runs):\n",
    "        key_acc = data_dict[key]['mean'][run]\n",
    "        num_batches = key_acc.shape[1]\n",
    "        num_tasks = key_acc.shape[0]\n",
    "        k_shot_acc = np.zeros([num_batches], dtype=np.float32)\n",
    "        for i in range(num_batches):\n",
    "            acc = 0.0\n",
    "            for j in range(num_tasks):\n",
    "                acc += key_acc[j,i]\n",
    "            k_shot_acc[i] = acc/ num_tasks\n",
    "        \n",
    "        k_shot_dict[key].append(k_shot_acc)\n",
    "        \n",
    "    k_shot_dict[key] = np.array(k_shot_dict[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_average_accuracy_along_training_path(data_mean, plot_name=None, is_cifar=False):\n",
    "    \"\"\"\n",
    "    Plot the average accuracy along the training path\n",
    "    \"\"\"\n",
    "    plt.clf()\n",
    "    K_FOR_CROSS_VAL = 3\n",
    "    avg_acc_dict = dict()\n",
    "    for key in data_mean:\n",
    "        data = data_mean[key]['mean'].mean(0)\n",
    "        num_tasks = data.shape[0]\n",
    "        avg_acc = np.zeros(num_tasks)\n",
    "        for i in range(num_tasks):\n",
    "            avg_acc[i] = np.mean(data[i,:i+1])\n",
    "#             if key == 'MULTI-TASK':\n",
    "#                 avg_acc[i] = np.mean(data)\n",
    "#             elif key == 'ICARL':\n",
    "#                 avg_acc[i] = np.mean(data[i,:i+1])\n",
    "#             elif key == 'GEM':\n",
    "#                 avg_acc[i] = np.mean(data[i,:i+1])\n",
    "                \n",
    "#             else:\n",
    "#                 avg_acc[i] = np.mean(data[i,:i+1])\n",
    "        print(key, avg_acc[-1])\n",
    "        avg_acc_dict[key] = avg_acc\n",
    "\n",
    "    \n",
    "    fig = plt.figure(figsize=(8,2.5))\n",
    "    ax = fig.add_axes([0.15, 0.21, 0.6, 0.75])\n",
    "    tasks = np.arange(1, num_tasks+1)\n",
    "    \n",
    "    colors = {'STL-p-MNIST':'-k', 'SGD-p-MNIST': 'C0', 'RLL-p-MNIST':'C1', 'STL-r-MNIST':'C2', 'SGD-r-MNIST': 'C3', 'RLL-r-MNIST':'C4'}\n",
    "#     , 'EWC': '-m', 'PI': '-b', 'MAS': '-y', \n",
    "#               'RWALK':'-g', 'PROG-NN':'C5--', 'GEM':'-c', 'A-GEM':'-r', 'MER': 'C6'}\n",
    "    \n",
    "        \n",
    "    for i, key in enumerate(data_mean):\n",
    "        if key == 'MULTI-TASK':\n",
    "            continue\n",
    "        else:\n",
    "            if key == 'STL':\n",
    "                ax.plot(tasks, avg_acc_dict[key],'%s'%(colors[key]), marker='^', markersize=7, lw=2, label=key)\n",
    "            else:\n",
    "                ax.plot(tasks, avg_acc_dict[key],'%s'%(colors[key]), lw=2, label=key)\n",
    "                \n",
    "#     line, =  ax.plot(tasks, avg_acc_dict['MULTI-TASK'],'%s'%(colors['MULTI-TASK']), lw=2, label='MULTI-TASK')\n",
    "#     line.set_dashes([2, 2, 10, 2])\n",
    "        \n",
    "#     if is_cifar:\n",
    "#         ax.legend(bbox_to_anchor=(1, 1), loc=2, borderaxespad=0.2)\n",
    "    ax.legend(bbox_to_anchor=(1, 1), loc=2, borderaxespad=0.2)\n",
    "    ax.set_xlabel('Tasks', size=20)\n",
    "    ax.set_ylabel('Avg Accuracy', size=20)\n",
    "    plt.xticks(tasks)\n",
    "    plt.grid()\n",
    "\n",
    "    \n",
    "    if plot_name is not None:\n",
    "        plt.savefig(plot_name)\n",
    "    else:\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_fgt(acc, key):\n",
    "    num_tasks = acc.shape[0] # Number of tasks\n",
    "    last_batch_dim = acc.shape[1] - 1 # Last batch dimension\n",
    "    fgt_msr = np.zeros([num_tasks-1]) # Not defined for first task. Store forgetting after each task\n",
    "    worst_case_fgt = np.zeros([num_tasks-1]) # Not defined for first task. Store forgetting after each task\n",
    "    for i in range(num_tasks):\n",
    "        if i == 0:\n",
    "            pass\n",
    "        else:\n",
    "            wst_fgt_i = []\n",
    "            fgt_i = 0.0\n",
    "            for j in range(i):\n",
    "                if key == 'GEM' or key == 'ICARL':\n",
    "                    fgt_per_task = np.amax(acc[:i,j]) - acc[i,j]\n",
    "                else:\n",
    "                    fgt_per_task = np.amax(acc[:i,last_batch_dim]) - acc[i,last_batch_dim]\n",
    "                        \n",
    "                fgt_i += fgt_per_task\n",
    "                wst_fgt_i.append(fgt_per_task)\n",
    "            fgt_msr[i-1] = fgt_i/ (j+1)\n",
    "            wst_fgt_i = np.array(wst_fgt_i)\n",
    "            worst_case_fgt[i-1] = np.max(wst_fgt_i)\n",
    "                \n",
    "    return fgt_msr, worst_case_fgt \n",
    "\n",
    "\n",
    "def average_acc_stats_across_runs(data, key):\n",
    "    \"\"\"\n",
    "    Compute the average accuracy statistics (mean and std) across runs\n",
    "    \"\"\"\n",
    "    num_runs = data.shape[0]\n",
    "    avg_acc = np.zeros(num_runs)\n",
    "    for i in range(num_runs):\n",
    "        if key == 'GEM':\n",
    "            avg_acc[i] = np.mean(data[i][-1])\n",
    "        else:\n",
    "            avg_acc[i] = np.mean(data[i][-1, -1])\n",
    "        \n",
    "    return avg_acc.mean()*100, avg_acc.std()*100\n",
    "\n",
    "def average_fgt_stats_across_runs(data, key):\n",
    "    \"\"\"\n",
    "    Compute the forgetting statistics (mean and std) across runs\n",
    "    \"\"\"\n",
    "    num_runs = data.shape[0]\n",
    "    fgt = np.zeros(num_runs)\n",
    "    wst_fgt = np.zeros(num_runs)\n",
    "    for i in range(num_runs):\n",
    "        fgt_i, wst_fgt_i = compute_fgt(data[i], key)\n",
    "        #print('{}, {}'.format(i, fgt_i))\n",
    "        fgt[i] = fgt_i[-1]\n",
    "        wst_fgt[i] = wst_fgt_i[-1]\n",
    "        \n",
    "    return fgt.mean(), fgt.std(), wst_fgt.mean(), wst_fgt.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# def populate_k_shot_acc_dict_with_varying_batches(data_dict, key, k_shot_dict):\n",
    "#     num_runs = data_dict[key]['mean'].shape[0]\n",
    "#     k_shot_dict[key] = []\n",
    "#     for run in range(num_runs):\n",
    "#         key_acc = data_dict[key]['mean'][run]\n",
    "#         num_tasks = key_acc.shape[0]\n",
    "#         # First compute the number of batches for each task (as total number of examples per task is different)\n",
    "#         batches_per_task = []\n",
    "#         for i in range(num_tasks):\n",
    "#             batches_per_task.append(np.max(np.nonzero(np.sum(key_acc[i], axis=1))))\n",
    "\n",
    "#         # Since the code above returned an index, so add '1' to get the count of batches for each task\n",
    "#         batches_per_task = np.array(batches_per_task) + 1\n",
    "#         max_batches = np.max(batches_per_task)\n",
    "#         k_shot_acc = np.zeros([max_batches], dtype=np.float32)\n",
    "    \n",
    "#         for i in range(max_batches):\n",
    "#             acc = 0.0\n",
    "#             task_count_with_this_batch = 0\n",
    "#             for j in range(num_tasks):\n",
    "#                 if i < batches_per_task[j]: # Only add accuracy if current task has that many batches\n",
    "#                     acc += key_acc[j,i,j]\n",
    "#                     task_count_with_this_batch += 1\n",
    "#                 else:\n",
    "#                     acc += key_acc[j,batches_per_task[j]-1,j]\n",
    "#             k_shot_acc[i] = acc/ num_tasks\n",
    "        \n",
    "#         # Store the average accuracy in the dictionary\n",
    "#         k_shot_dict[key].append(k_shot_acc)\n",
    "    \n",
    "#     k_shot_dict[key] = np.array(k_shot_dict[key])\n",
    "    \n",
    "#     return batches_per_task    \n",
    "\n",
    "\n",
    "# def compute_fgt(acc, key):\n",
    "#     num_tasks = acc.shape[0] # Number of tasks\n",
    "#     last_batch_dim = acc.shape[1] - 1 # Last batch dimension\n",
    "#     fgt_msr = np.zeros([num_tasks-1]) # Not defined for first task. Store forgetting after each task\n",
    "#     worst_case_fgt = np.zeros([num_tasks-1]) # Not defined for first task. Store forgetting after each task\n",
    "#     for i in range(num_tasks):\n",
    "#         if i == 0:\n",
    "#             pass\n",
    "#         else:\n",
    "#             wst_fgt_i = []\n",
    "#             fgt_i = 0.0\n",
    "#             for j in range(i):\n",
    "#                 if key == 'GEM' or key == 'ICARL':\n",
    "#                     fgt_per_task = np.amax(acc[:i,j]) - acc[i,j]\n",
    "#                 else:\n",
    "#                     fgt_per_task = np.amax(acc[:i,last_batch_dim,j]) - acc[i,last_batch_dim]\n",
    "                        \n",
    "#                 fgt_i += fgt_per_task\n",
    "#                 wst_fgt_i.append(fgt_per_task)\n",
    "#             fgt_msr[i-1] = fgt_i/ (j+1)\n",
    "#             wst_fgt_i = np.array(wst_fgt_i)\n",
    "#             worst_case_fgt[i-1] = np.max(wst_fgt_i)\n",
    "                \n",
    "#     return fgt_msr, worst_case_fgt  \n",
    "\n",
    "\n",
    "# def compute_fgt_with_varying_batches(data_dict, batches_per_task):\n",
    "#     fgt_msr = dict()\n",
    "#     for key in data_dict:\n",
    "#         acc = data_dict[key]\n",
    "#         num_tasks = acc.shape[0] # Number of tasks\n",
    "#         last_batch_acc_for_all_tasks = np.zeros([num_tasks, num_tasks])\n",
    "        \n",
    "#         # Compute the last batch performance for each task\n",
    "#         for i in range(num_tasks):\n",
    "#             last_batch_acc_for_all_tasks[i] = acc[i][batches_per_task[i]-1]\n",
    "        \n",
    "#         fgt_msr[key] = np.zeros([num_tasks-1]) # Not defined for first task. Store forgetting after each task\n",
    "#         for i in range(num_tasks):\n",
    "#             if i == 0:\n",
    "#                 pass\n",
    "#             else:\n",
    "#                 fgt_i = 0.0\n",
    "#                 for j in range(i):\n",
    "#                     fgt_i += (np.amax(last_batch_acc_for_all_tasks[:i,j]) - last_batch_acc_for_all_tasks[i,j])\n",
    "#                 fgt_msr[key][i-1] = fgt_i/ (j+1)\n",
    "                \n",
    "#     return fgt_msr\n",
    "\n",
    "# def average_acc_stats_across_runs(data, key):\n",
    "#     \"\"\"\n",
    "#     Compute the average accuracy statistics (mean and std) across runs\n",
    "#     \"\"\"\n",
    "#     num_runs = data.shape[0]\n",
    "#     avg_acc = np.zeros(num_runs)\n",
    "#     for i in range(num_runs):\n",
    "#         if key == 'GEM':\n",
    "#             avg_acc[i] = np.mean(data[i][-1])\n",
    "#         else:\n",
    "#             avg_acc[i] = np.mean(data[i][-1, -1])\n",
    "        \n",
    "#     return avg_acc.mean()*100, avg_acc.std()*100\n",
    "\n",
    "# def average_fgt_stats_across_runs(data, key):\n",
    "#     \"\"\"\n",
    "#     Compute the forgetting statistics (mean and std) across runs\n",
    "#     \"\"\"\n",
    "#     num_runs = data.shape[0]\n",
    "#     fgt = np.zeros(num_runs)\n",
    "#     wst_fgt = np.zeros(num_runs)\n",
    "#     for i in range(num_runs):\n",
    "#         fgt_i, wst_fgt_i = compute_fgt(data[i], key)\n",
    "#         #print('{}, {}'.format(i, fgt_i))\n",
    "#         fgt[i] = fgt_i[-1]\n",
    "#         wst_fgt[i] = wst_fgt_i[-1]\n",
    "        \n",
    "#     return fgt.mean(), fgt.std(), wst_fgt.mean(), wst_fgt.std()\n",
    "        \n",
    "\n",
    "# def plot_k_shot_performance_task_view(n, data_dict, keys, plt_name):\n",
    "#     plt.figure(figsize=(14, 7))\n",
    "#     num_windows = len(keys)\n",
    "#     for i, key in enumerate(keys):\n",
    "#         data = data_dict[key]\n",
    "#         num_tasks = data.shape[0]\n",
    "#         plt.subplot(math.ceil((num_windows+1)/2), math.ceil((num_windows+1)/2), (i+1))\n",
    "#         for k in range(n):\n",
    "#             acc = np.zeros([num_tasks])\n",
    "#             for task in range(num_tasks):\n",
    "#                 acc[task] = data[task, k, task]\n",
    "#             plt.plot(np.arange(1,num_tasks+1), acc, label='%d-shot'%(k))\n",
    "#         plt.xlabel('Tasks-%s'%(key))\n",
    "#         plt.ylabel('Avg_Acc')\n",
    "#         plt.xticks(np.arange(1, num_tasks+1))\n",
    "#     plt.tight_layout()\n",
    "#     #plt.legend(loc='best')\n",
    "#     plt.legend(loc=6, bbox_to_anchor=(1, 0.5))\n",
    "#     plt.savefig(plt_name)\n",
    "    \n",
    "# def plot_k_shot_performance_method_view(n, data_dict, plt_name):\n",
    "#     plt.figure(figsize=(14, 7))\n",
    "#     for k in range(n):\n",
    "#         plt.subplot(n//2, n//2, (k+1))\n",
    "#         for i, key in enumerate(data_dict):\n",
    "#             num_tasks = data_dict[key].shape[0]\n",
    "#             acc = np.zeros(num_tasks)\n",
    "#             for task in range(num_tasks):\n",
    "#                 acc[task] = data_dict[key][task, k, task]\n",
    "#             plt.plot(np.arange(1,num_tasks+1), acc, label=key)\n",
    "#         plt.xlabel('Tasks(%d-shot)'%(k))\n",
    "#         plt.ylabel('Avg_Acc')\n",
    "#         plt.xticks(np.arange(1, num_tasks+1))\n",
    "#     plt.tight_layout()\n",
    "#     plt.legend(loc='best')\n",
    "#     #plt.savefig(plt_name)    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def plot_average_accuracy_along_training_path(data_mean, plot_name=None, is_cifar=False):\n",
    "#     \"\"\"\n",
    "#     Plot the average accuracy along the training path\n",
    "#     \"\"\"\n",
    "#     plt.clf()\n",
    "#     K_FOR_CROSS_VAL = 3\n",
    "#     avg_acc_dict = dict()\n",
    "#     for key in data_mean:\n",
    "#         data = data_mean[key]['mean'].mean(0)\n",
    "#         num_tasks = data.shape[0]\n",
    "#         avg_acc = np.zeros(num_tasks)\n",
    "#         for i in range(num_tasks):\n",
    "#             avg_acc[i] = np.mean(data[i,:i+1])\n",
    "# #             if key == 'MULTI-TASK':\n",
    "# #                 avg_acc[i] = np.mean(data)\n",
    "# #             elif key == 'ICARL':\n",
    "# #                 avg_acc[i] = np.mean(data[i,:i+1])\n",
    "# #             elif key == 'GEM':\n",
    "# #                 avg_acc[i] = np.mean(data[i,:i+1])\n",
    "                \n",
    "# #             else:\n",
    "# #                 avg_acc[i] = np.mean(data[i,:i+1])\n",
    "#         print(key, avg_acc[-1])\n",
    "#         avg_acc_dict[key] = avg_acc\n",
    "\n",
    "    \n",
    "#     fig = plt.figure(figsize=(8,2.5))\n",
    "#     ax = fig.add_axes([0.15, 0.21, 0.6, 0.75])\n",
    "#     tasks = np.arange(1, num_tasks+1)\n",
    "    \n",
    "#     colors = {'STL':'-k', 'SGD': 'C0', 'RLL':'C1'}\n",
    "# #     , 'EWC': '-m', 'PI': '-b', 'MAS': '-y', \n",
    "# #               'RWALK':'-g', 'PROG-NN':'C5--', 'GEM':'-c', 'A-GEM':'-r', 'MER': 'C6'}\n",
    "    \n",
    "        \n",
    "#     for i, key in enumerate(data_mean):\n",
    "#         if key == 'MULTI-TASK':\n",
    "#             continue\n",
    "#         else:\n",
    "#             if key == 'A-GEM':\n",
    "#                 ax.plot(tasks, avg_acc_dict[key],'%s'%(colors[key]), marker='^', markersize=7, lw=2, label=key)\n",
    "#             else:\n",
    "#                 ax.plot(tasks, avg_acc_dict[key],'%s'%(colors[key]), lw=2, label=key)\n",
    "                \n",
    "# #     line, =  ax.plot(tasks, avg_acc_dict['MULTI-TASK'],'%s'%(colors['MULTI-TASK']), lw=2, label='MULTI-TASK')\n",
    "# #     line.set_dashes([2, 2, 10, 2])\n",
    "        \n",
    "#     if is_cifar:\n",
    "#         ax.legend(bbox_to_anchor=(1, 1), loc=2, borderaxespad=0.2)\n",
    "    \n",
    "#     ax.set_xlabel('Tasks', size=20)\n",
    "#     ax.set_ylabel('Avg Accuracy', size=20)\n",
    "#     plt.xticks(tasks)\n",
    "#     plt.grid()\n",
    "\n",
    "    \n",
    "#     if plot_name is not None:\n",
    "#         plt.savefig(plot_name)\n",
    "#     else:\n",
    "#         plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# def get_zero_shot_perf(data_mean_ohot, data_mean_je):\n",
    "#     \"\"\"\n",
    "#     Plot the zero-shot performance against the number of tasks\n",
    "#     \"\"\"\n",
    "#     zero_shot_ohot_perf = dict()\n",
    "#     zero_shot_je_perf = dict()\n",
    "    \n",
    "#     for key in data_mean_ohot:\n",
    "#         if key == 'MULTI-TASK' or key == 'GEM':\n",
    "#             continue\n",
    "        \n",
    "#         data_ohot = data_mean_ohot[key]['mean'].mean(0)\n",
    "#         data_je = data_mean_je[key]['mean'].mean(0)\n",
    "#         num_tasks = data_ohot.shape[0] \n",
    "        \n",
    "#         zst_ohot_perf = np.zeros(num_tasks)\n",
    "#         zst_je_perf = np.zeros(num_tasks)\n",
    "        \n",
    "#         #if (data_ohot.shape[0] != num_tasks) or (data_je.shape[0] != num_tasks):\n",
    "#         #    continue\n",
    "            \n",
    "#         for i in range(num_tasks):\n",
    "#             zst_ohot_perf[i] = data_ohot[i,0,i]\n",
    "#             zst_je_perf[i] = data_je[i,0,i]\n",
    "            \n",
    "#         zero_shot_ohot_perf[key] = zst_ohot_perf\n",
    "#         zero_shot_je_perf[key] = zst_je_perf\n",
    "    \n",
    "#     return zero_shot_ohot_perf, zero_shot_je_perf\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# def bar_plot_k_shot_performance(data_dict, shot, is_cifar=False, plt_name=None):\n",
    "#     num_tasks = data_dict['VAN'].shape[0]\n",
    "#     ind = np.arange(1, num_tasks+1) # the x locations for the groups\n",
    "#     width = 0.15 # the width of the bars\n",
    "#     colors = ['r', 'g', 'b', 'c', 'y']\n",
    "#     plt.clf()\n",
    "#     for col_ind, key in enumerate(data_dict):\n",
    "#         acc = np.zeros([num_tasks])\n",
    "#         for task in range(num_tasks):\n",
    "#             acc[task] = data_dict[key][task,shot,task]\n",
    "#         p1 = plt.bar(ind+width*col_ind, acc, width, color='%s'%(colors[col_ind]), bottom=0, label=key)\n",
    "    \n",
    "#     plt.xticks(np.arange(1, num_tasks+1)) # add loads of ticks\n",
    "\n",
    "#     plt.gca().margins(x=0)\n",
    "#     plt.gcf().canvas.draw()\n",
    "#     tl = plt.gca().get_xticklabels()\n",
    "#     maxsize = max([t.get_window_extent().width for t in tl])\n",
    "#     m = 0.5 # inch margin\n",
    "#     s = maxsize/plt.gcf().dpi*num_tasks+10*m\n",
    "#     margin = m/plt.gcf().get_size_inches()[0]\n",
    "\n",
    "#     plt.gcf().subplots_adjust(left=margin, right=1.-margin)\n",
    "#     plt.gcf().set_size_inches(s, plt.gcf().get_size_inches()[1])\n",
    "    \n",
    "#     if is_cifar:\n",
    "#         plt.title('%d-Shot Performance'%(shot*5))\n",
    "#     else:\n",
    "#         plt.title('%d-Shot Performance'%(shot))\n",
    "#     plt.legend(loc=6, bbox_to_anchor=(1, 0.8))\n",
    "#     plt.xlabel('Tasks')\n",
    "#     plt.ylabel('Avg_Acc')    \n",
    "#     #plt.show()\n",
    "#     plt.savefig(plt_name)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = np.array(range(10))\n",
    "# np.random.shuffle(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['SGD-p-MNIST', 'STL-p-MNIST', 'RLL-p-MNIST', 'SGD-r-MNIST', 'RLL-r-MNIST', 'STL-r-MNIST']\n"
     ]
    }
   ],
   "source": [
    "PREFIX = 'logs/'\n",
    "# print(os.listdir(PREFIX))\n",
    "# multi_task_pickle = PREFIX+'multi_task/PERMUTE_MNIST_HERDING_False_FC-S_False_True_VAN_0_0_10_False_25-18-09-10-10-41.pickle'\n",
    "# van_pickle = PREFIX+'PERMUTE_MNIST_HERDING_False_FC-S_False_True_VAN_0_0_10_False_25-18-11-08-16-40.pickle'\n",
    "# ewc_pickle = PREFIX+'PERMUTE_MNIST_HERDING_False_FC-S_False_True_EWC_10_0_10_False_25-18-11-08-17-55.pickle'\n",
    "# mas_pickle = PREFIX+'PERMUTE_MNIST_HERDING_False_FC-S_False_True_MAS_0_1_10_False_25-18-11-08-16-40.pickle'\n",
    "# rwalk_pickle = PREFIX+'PERMUTE_MNIST_HERDING_False_FC-S_False_True_RWALK_1_0_10_False_25-18-11-08-18-06.pickle'\n",
    "# pnn_pickle = PREFIX+'PERMUTE_MNIST_HERDING_False_FC-S_False_True_PNN_0_0_10_False_25-18-11-08-16-40.pickle'\n",
    "# gem_pickle = PREFIX+'gem_mnist_5_runs.pickle'\n",
    "# a_gem_pickle = PREFIX+'PERMUTE_MNIST_HERDING_False_FC-S_False_True_A-GEM_0_0_10_False_25-18-11-08-19-27.pickle'\n",
    "items = os.listdir(PREFIX)\n",
    "MODELS = []\n",
    "for item in items:\n",
    "    if 'RLL' in item and 'p-MNIST' in item and 'pickle' in item:\n",
    "        rll_pickle = os.path.join(PREFIX,item)\n",
    "        MODELS.append('RLL-p-MNIST')\n",
    "    if 'SGD' in item and 'p-MNIST' in item and 'pickle' in item:\n",
    "        sgd_pickle = os.path.join(PREFIX,item)\n",
    "        MODELS.append('SGD-p-MNIST')\n",
    "    if 'STL' in item and 'p-MNIST' in item and 'pickle' in item:\n",
    "        stl_pickle = os.path.join(PREFIX,item)\n",
    "        MODELS.append('STL-p-MNIST')\n",
    "    if 'RLL' in item and 'r-MNIST' in item and 'pickle' in item:\n",
    "        rll_pickle = os.path.join(PREFIX,item)\n",
    "        MODELS.append('RLL-r-MNIST')\n",
    "    if 'SGD' in item and 'r-MNIST' in item and 'pickle' in item:\n",
    "        sgd_pickle = os.path.join(PREFIX,item)\n",
    "        MODELS.append('SGD-r-MNIST')\n",
    "    if 'STL' in item and 'r-MNIST' in item and 'pickle' in item:\n",
    "        stl_pickle = os.path.join(PREFIX,item)\n",
    "        MODELS.append('STL-r-MNIST')\n",
    "    \n",
    "\n",
    "NUM_RUNS = 5\n",
    "print(MODELS)\n",
    "# MODELS = ['MULTI-TASK', 'VAN', 'EWC', 'MAS', 'RWALK', 'PNN', 'GEM', 'A-GEM']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data_mean = dict()\n",
    "if 'RLL-r-MNIST' in MODELS:\n",
    "    populate_data_dict(data_mean, 'RLL-r-MNIST', rll_pickle)\n",
    "if 'SGD-r-MNIST' in MODELS:\n",
    "    populate_data_dict(data_mean, 'SGD-r-MNIST', sgd_pickle)\n",
    "if 'STL-r-MNIST' in MODELS:\n",
    "    populate_data_dict(data_mean, 'STL-r-MNIST', stl_pickle)\n",
    "if 'RLL-p-MNIST' in MODELS:\n",
    "    populate_data_dict(data_mean, 'RLL-p-MNIST', rll_pickle)\n",
    "if 'SGD-p-MNIST' in MODELS:\n",
    "    populate_data_dict(data_mean, 'SGD-p-MNIST', sgd_pickle)\n",
    "if 'STL-p-MNIST' in MODELS:\n",
    "    populate_data_dict(data_mean, 'STL-p-MNIST', stl_pickle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_k_shot_acc = dict()\n",
    "if 'RLL-p-MNIST' in MODELS:\n",
    "    populate_k_shot_acc_dict(data_mean, 'RLL-p-MNIST', avg_k_shot_acc)\n",
    "if 'SGD-p-MNIST' in MODELS:\n",
    "    populate_k_shot_acc_dict(data_mean, 'SGD-p-MNIST', avg_k_shot_acc)\n",
    "if 'STL-p-MNIST' in MODELS:\n",
    "    populate_k_shot_acc_dict(data_mean, 'STL-p-MNIST', avg_k_shot_acc)\n",
    "if 'RLL-r-MNIST' in MODELS:\n",
    "    populate_k_shot_acc_dict(data_mean, 'RLL-r-MNIST', avg_k_shot_acc)\n",
    "if 'SGD-r-MNIST' in MODELS:\n",
    "    populate_k_shot_acc_dict(data_mean, 'SGD-r-MNIST', avg_k_shot_acc)\n",
    "if 'STL-r-MNIST' in MODELS:\n",
    "    populate_k_shot_acc_dict(data_mean, 'STL-r-MNIST', avg_k_shot_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RLL-r-MNIST 0.9077299926191568\n",
      "SGD-r-MNIST 0.42834000289328406\n",
      "STL-r-MNIST 0.9131599923849105\n",
      "RLL-p-MNIST 0.9077299926191568\n",
      "SGD-p-MNIST 0.42834000289328406\n",
      "STL-p-MNIST 0.9131599923849105\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'RLL-r-MNIST'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_106984/3667530016.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplot_average_accuracy_along_training_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'mnist_average_accuracy.pdf'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_106984/4243244823.py\u001b[0m in \u001b[0;36mplot_average_accuracy_along_training_path\u001b[0;34m(data_mean, plot_name, is_cifar)\u001b[0m\n\u001b[1;32m     41\u001b[0m                 \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mavg_acc_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'%s'\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmarker\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'^'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmarkersize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlw\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m                 \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mavg_acc_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'%s'\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlw\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;31m#     line, =  ax.plot(tasks, avg_acc_dict['MULTI-TASK'],'%s'%(colors['MULTI-TASK']), lw=2, label='MULTI-TASK')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'RLL-r-MNIST'"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "findfont: Font family ['sans-serif'] not found. Falling back to DejaVu Sans.\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Helvetica\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x180 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_average_accuracy_along_training_path(data_mean, 'mnist_average_accuracy.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
